# Sign-language-translator
dynamic sign language translator
Project Documentation
________________________________________
Project Overview
The project focuses on creating a sign language recognition system that integrates real-time gesture detection and recognition using machine learning, webcam inputs, and user-friendly interaction. The system will also include speech synthesis to translate recognized gestures into spoken words, providing an accessible and interactive platform.
________________________________________
Features
1.	Real-Time Gesture Recognition:
* It will use TensorFlow.js and a kNN classifier to detect and classify hand gestures.
*	It will implement a training system to add new gesture examples dynamically.
3.	Webcam Integration:
*	Utilizes the getUserMedia API for video feed access.
*	Captures video frames using the Canvas API for processing.
4.	User-Friendly Interface:
*  It will feature an intuitive UI for gesture training, feedback, and interaction.
*	Display captured images with user-provided labels.
5.	Speech Synthesis:
*	pending work
6.	Video Call Integration:
*	pending
7.	Responsive Design:
*	The UI aims to adapt to various devices, ensuring a seamless user experience.
________________________________________
Technology Stack
•	Frontend:
*	HTML, CSS, JavaScript
*	Responsive design with Flexbox
•	Machine Learning:
*	TensorFlow.js for kNN classifier
•	APIs and Libraries:
* getUserMedia API for webcam integration
* Canvas API for frame capturing
•	Deployment:
*	GitHub 
________________________________________


